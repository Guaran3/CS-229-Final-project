<head>

<meta name="description" content="">

<meta name="keywords" content="">

<meta name="author" content="">





</head>

<body bgcolor="#ffffff" topmargin="0" leftmargin="0" marginheight="0" marginwidth="0">





<table border="0" cellpadding="0" cellspacing="0" align="right">

<tr>

<td><!--***************************************************************************************-->

<A onmouseover="window.status&#13;&#10;='Homepage';

 return true"

 onmouseout ="window.status=''; return true" href="http://www.cs.manchester.ac.uk/" >

home</A>&nbsp;&nbsp;<font color="#660099">|</font>&nbsp;&nbsp; <!--***************************************************************************************-->



</td>



<td><!--***************************************************************************************-->

<A onmouseover="window.status&#13;&#10;='Research';

 return true"

 onmouseout ="window.status=''; return true" href="http://www.cs.manchester.ac.uk/ai/" >

research</A>&nbsp;&nbsp;<font color="#660099">|</font>&nbsp;&nbsp; <!--***************************************************************************************-->

</td>





<td><!--***************************************************************************************-->

<A onmouseover="window.status&#13;&#10;='People

 in the group'; return true"

 onmouseout ="window.status=''; return true" href="http://www.cs.manchester.ac.uk/ai/people/" >

people</A>&nbsp;&nbsp;<font color="#660099">|</font>&nbsp;&nbsp; <!--***************************************************************************************-->

</td>



</tr>

</table>



<table border="0" cellpadding="0" cellspacing="0" width="436">



<tr>

<td width="47" valign="top"><!--***************************************************************************************-->&nbsp; 

<!--***************************************************************************************-->

</td>

<td><!--***************************************************************************************-->

<a href="http://www.manchester.ac.uk/"

 onMouseOver 

="window.status='image1'; return true"

 onMouseOut="window.status=''; return true" 

      align="right" valign  ="top" 

     ; <P 

     ><IMG alt="University Logo" title="Manchester Est. 1824" src="http://www.cs.manchester.ac.uk/ai/pictures/icons/est1824.gif"> <!--***************************************************************************************-->

</td></tr></table></body>
<head>

   <link href="http://www.cs.manchester.ac.uk/css/_print.css"

    type="text/css" rel="stylesheet" media="print" />



    <link href="http://www.cs.manchester.ac.uk/css/_base.css"

    type="text/css" rel="stylesheet" media="screen" />

    <style type="text/css" media="screen">

    /*<![CDATA[*/

    <!--

    @import url(http://www.cs.manchester.ac.uk/css/_layout.css);

    @import url(http://www.cs.manchester.ac.uk/css/_navigation.css);

    @import url(http://www.cs.manchester.ac.uk/css/_forms.css);

    @import url(http://www.cs.manchester.ac.uk/css/_boxes.css);

    -->

    /*]]>*/



    .currentsection  {

	 background-color: #f0f0ff; 

	 color:#000;

	 display: block; 

	 font-weight:normal;

	 padding: 4px 4px 5px 4px;

	 text-decoration:none; 

    }

    .multilevel-linkdiv-0 {

	 background-color: #f0f0ff; 

	 margin-left: 1.0em;

         text-align: left

    }

    a.greylink:link    { color: #c0c0c0; }

    a.greylink:visited { color: #d0d0d0; }

		

    .lined {

	 border-style: solid;

	 border-color: #006073;

	 border-bottom-width: 0px;

	 border-top-width: 1px;

	 border-left-width: 0px;

	 border-right-width: 0px;

    }

    table, caption {

      font-size: inherit;

      font-weight: inherit;

      font-style: inherit;

      font-variant: inherit;

    }

    </style>



    <style type="text/css" media="screen">

    /*<![CDATA[*/

    <!--

    .section {margin-left: 4em}

    body { background-image: url(http://www.cs.manchester.ac.uk/ai//pictures/icons/logoleft.gif); }

    div.locator { background-color: #6666cc; background-image: url(); background-repeat: no-repeat; border: none; margin: 1px 0 0 0; padding: 0; width: 184px; height: 92px; }

    -->

    /*]]>*/

    </style>

<!--  End of Style Sheet CSS -->

</head>




<head>

<title>Informative Vector Machine - MATLAB Software</title>

</head>



<body><div class="section">



<h1>IVM Software</h1>



This page describes examples of how to use the informative vector machine Software (IVM).




<p>The IVM software can be downloaded
<a href="http://www.cs.man.ac.uk/neill-bin/software/downloadForm.cgi?toolbox=ivm">here</a>.
<h2>Release Information</h2>
<p>Current release is 0.4.
<p>As well as downloading the IVM software you need to obtain the toolboxes specified below.
    <table>
    <tr>
    <td width="65%"><b>Toolbox</b></td>
    <td width="35%"><b>Version</b></td>
    </tr><tr><td><a href="http://www.cs.man.ac.uk/~neill/kern/downloadFiles/vrs0p165">KERN</a></td><td> 0.165</td></tr>
<tr><td><a href="http://www.cs.man.ac.uk/~neill/prior/downloadFiles/vrs0p131">PRIOR</a></td><td> 0.131</td></tr>
<tr><td><a href="http://www.cs.man.ac.uk/~neill/optimi/downloadFiles/vrs0p132">OPTIMI</a></td><td> 0.132</td></tr>
<tr><td><a href="http://www.cs.man.ac.uk/~neill/rochol/downloadFiles/vrs0p12">ROCHOL</a></td><td> 0.12</td></tr>
<tr><td><a href="http://www.cs.man.ac.uk/~neill/ndlutil/downloadFiles/vrs0p155">NDLUTIL</a></td><td> 0.155</td></tr>
<tr><td><a href="http://www.cs.man.ac.uk/~neill/mltools/downloadFiles/vrs0p123">MLTOOLS</a></td><td> 0.123</td></tr>
<tr><td><a href="http://www.cs.man.ac.uk/~neill/datasets/downloadFiles/vrs0p131">DATASETS</a></td><td> 0.131</td></tr>
<tr><td><a href="http://www.cs.man.ac.uk/~neill/noise/downloadFiles/vrs0p14">NOISE</a></td><td> 0.14</td></tr>
</table>



<p>Finally you will also need the <a href="http://www.ncrg.aston.ac.uk/netlab/index.php">NETLAB toolbox</a> in your path and Anton Schwaighofer's SVM light MATLAB interface, available <a href="http://ida.first.fraunhofer.de/~anton/software.html">here</a> to run the <code>demThreeFive</code> example which compares with <a href="http://svmlight.joachims.org/">SVM light</a> version 5.00.





<h2>Examples</h2>

<h2><code>demClassification1</code></h2>

<p>The first example given is <code>demClassification1</code> which is a simple classification data set, where only one direction of the input is relevant in determining the decision boundary. An ARD MLP kernel is used in combination with a linear kernel. The ARD parameters in the linear and MLP kernel are constrained to be the same by the line:

<p><code>

% Constrain the ARD parameters in the MLP and linear kernels to be the same.<br>

model.kern = cmpndTieParameters(model.kern, {[4, 7], [5, 8]});

</code>

<p>The resulting classification is shown below.

<p><center><img src="demClassificationOne1.png"><br>

Decision boundary from the <code>demClassification1.m</code> example. Postive class is red circles, negative class green crosses and active points are yellow dots. Decision boundary shown in red, contours at 0.25 and 0.75 probability shown in blue.</center>





<h2><code>demClassification2</code></h2>

<p>The second example attempts to learn a Gaussian process give data that is sampled from a Gaussian process. The code is <code>demClassification2</code>. The underlying Gaussian process is based on an RBF kernel with variance inverse width 10. The IVM learns an inverse width of 15 and gives the classification is shown below.

<p><center><img src="demClassificationTwo2.png"><br>

Decision boundary from the <code>demClassification2.m</code> example. Postive class is red circles, negative class green crosses and active points are yellow dots. Decision boundary shown in red, contours at 0.25 and 0.75 probability shown in blue.</center>



<h2><code>demClassification3</code></h2>

<p>This example is similar to <code>demClassification2</code>, only now there is a null category region in the data (a region of low data density between the classes). The example is for comparison with the null category noise model.



<p><center><img src="demClassificationThree3.png"><br>

Decision boundary from the <code>demClassification3.m</code> example. Postive class is red circles, negative class green crosses and active points are yellow dots. Decision boundary shown in red, contours at 0.25 and 0.75 probability shown in blue.</center>



<h2><code>demOrdered1</code></h2>

<p>In this example the ordered categorical noise model is used (ordinal regression). The data is a simple data set for which a linear one dimensional model suffices. The IVM is given a combination of an RBF and linear kernel with ARD.For the ordered categorical case there are several parameters associated with the noise model (in particular the category widths), these are learnt too. The model learns that the system is linear and only one direction is important. The resulting classification is given below.



<p><center><img src="demOrderedOne1.png"><br>

Decision boundary from the <code>demOrdered1.m</code> example. Class 0 - red cross, Class 1 - green circles, Class 2 - blue crosses, Class 3 - cyan asterisks, Class 4 - pink squares, Class 5 - yellow diamonds. Class 6 - red triangles. Active points are yellow dots, note that because the kernel is linear by now the most informative points tend to be at the extrema. Decision boundaries shown in red, contours at 0.25 and 0.75 probability shown in blue.</center>



<h2><code>demOrdered2</code></h2>

<p>Another example with the ordered categorical noise model, here the data is radial, the categories being along the radius of a circle. The IVM is given a combination of an RBF and linear kernel with ARD. Again there are several parameters associated with the noise model, and these are learnt using <code>ivmOptimiseNoise</code>. The resulting classification is given below.



<p><center><img src="demOrderedTwo2.png"><br>

Decision boundary from the <code>demOrdered1.m</code> example. Class 0 - red cross, Class 1 - green circles, Class 2 - blue crosses, Class 3 - cyan asterisks, Class 4 - pink squares, Class 5 - yellow diamonds. Class 6 - red triangles. Active points are yellow dots, note that because the kernel is linear by now the most informative points tend to be at the extrema. Decision boundaries shown in red, contours at 0.25 and 0.75 probability shown in blue.</center>





<h2><code>demRegression1</code></h2>

<p>In this example the Gaussian noise model is used (standard regression). The data is sampled from a Gaussian process, only one input dimension is important. The IVM is given a combination of an RBF and linear kernel with ARD. The resulting regression is given below.



<p><center><img src="demRegressionOne1.png"><br>

Regression from the example <code>demRegression1.m</code>. Targets are red dots and active points are yellow dots.</center>



<h2><code>demRegression2</code></h2>

<p>A second example with Gaussian noise, sampled from a Gaussian process, but this time with differing length scales.



<p><center><img src="demRegressionTwo2.png"><br>

Regression from the example <code>demRegression2.m</code>. Targets are red dots and active points are yellow dots.</center>



<h2>Benchmark Data Sets</h2>



The function <code>ivmGunnarData</code> allows you to test the IVM on Gunnar Raetsch's benchmark data sets. Download the data sets, <a href="http://ida.first.fraunhofer.de/projects/bench/benchmarks.htm">from here</a> and expand the ringnorm data set into '$DATASETSDIRECTORY/gunnar/ringnorm'. Then run the following script.



<p>

<code>

&gt;&gt;ivmGunnarData('ringnorm', 1, {'rbf', 'bias', 'white'}, 1, 100)<br>

...<br>

<br>

Final model:<br>

IVM Model:<br>

 Noise Model:<br>

  Probit bias on process 1: 0.0439<br>

  Probit Sigma2: 0.0000<br>

 Kernel:<br>

  Compound kernel:<br>

    RBF inverse width: 0.0866 (length scale 3.3984)<br>

    RBF variance: 1.2350<br>

    Bias Variance: 8.2589<br>

    White Noise Variance: 0.0000<br>

Test Error 0.0183<br>

Model likelihood -56.7120<br>

</code>



<p>You can try any of the data sets by replacing ringnorm with the relevant data set (note that they don't all work with only 100 active points inas in the example above, for example the 'banana' data set needs 200 active points to get a reasonable result,

<p>

<code>

&gt;&gt; ivmGunnarData('banana', 1, {'rbf', 'bias', 'white'}, 1, 200)<br>

...<br><br>

Final model:<br>

IVM Model:<br>

 Noise Model:<br>

  Probit bias on process 1: 0.1067<br>

  Probit Sigma2: 0.0000<br>

 Kernel:<br>

  Compound kernel:<br>

    RBF inverse width: 1.6411 (length scale 0.7806)<br>

    RBF variance: 0.2438<br>

    Bias Variance: 0.0000<br>

    White Noise Variance: 0.0148<br>

Test Error 0.1129<br>

Model likelihood 175.3588<br>

</code>

</p>



<p><center><img src="demBanana1.png"><br>

Decision boundary from the banana example. Postive class is red circles, negative class green crosses and active points are yellow dots. Decision boundary shown in red, contours at 0.25 and 0.75 probability shown in blue.</center>



<h2>Null Category Noise Model</h2>



<h2>Examples</h2>



<p>The toy data example in the papers can be recreated using:



<p><code>

&gt;&gt; demUnlabelled1

</code>



<p>and leads to the decision boundary given below. A standard IVM based classifier can be run on the data using

<p>

<code>

&gt;&gt; demUnlabelled2

</code>



<p><center><img src="demUnlabelledOne1.png"><img src="demUnlabelledOne2.png"><br>

The null category noise model run on toy data. <i>Top</i>: using the null category, the true nature of the decision boundary is recovered. <i>Bottom</i>: the standard IVM, does not recover the true decision boundary.</center>



<p>The other USPS digit classification example given in the NIPS paper can be re-run with:

<p>

<code>

&gt;&gt; demThreeFive

</code>



<p>Be aware that this code can take some time to run. The results, in the form of averaged area under ROC curve against probability of missing label, can be plotted using



<p>

<code>

&gt;&gt; demThreeFiveResults

</code>

<center><image src="demThreeFive.png"><br>Plot of average area under ROC curve against probability of label being present. The red line is the standard IVM based classifier, the blue dotted line is the null category noise model based classifier, the green dash-dot line is the a normal SVM and the mauve dashed line is the transductive SVM.

</center>



</div></body>

<p><center>Page updated on Sat Jan 13 01:05:38 2007</center><!-- footer -->



<body>

    <div id="footer">

      <div class="links">

        <p>

          | 

          <a href="http://www.manchester.ac.uk/aboutus/documents/disclaimer/"

             title="Disclaimer">Disclaimer</a> |

             <a href="http://www.manchester.ac.uk/aboutus/documents/privacy/"

             title="Privacy">Privacy</a> |

             <a href="http://www.manchester.ac.uk/aboutus/documents/copyright/"

             title="Copyright Notice">Copyright notice</a> |

             <a href="http://www.manchester.ac.uk/aboutus/documents/accessibility/"

             title="Accessibility">Accessibility</a> |

             <a href="http://www.manchester.ac.uk/aboutus/documents/foi/"

             title="Freedom of information">Freedom of information</a> | 

             <a href="http://www.manchester.ac.uk/aboutus/contact/feedback/"

             title="Feedback">Feedback</a> |

        </p>



      </div>

      <div class="pagestatus">

        <p>Please contact

          <a href="mailto:webmaster.cs@manchester.ac.uk">webmaster.cs@manchester.ac.uk</a>

          with comments and suggestions

        </p>

      </div>

    </div>



  </body>

